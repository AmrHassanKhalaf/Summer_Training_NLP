{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMucPdghZn3qOVlFMOsecQC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmrHassanKhalaf/Summer_Training_NLP/blob/main/Sec_5/Task_2/Sec_5_T_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using gensim, fasttext, glove"
      ],
      "metadata": {
        "id": "lZ4eamPMZ178"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--FAjPd8ZAqX"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"machine learning is fun\",\n",
        "    \"deep learning improves ai\",\n",
        "    \"natural language processing with neural networks\",\n",
        "    \"word embeddings capture semantic meaning\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2-zNS9laK3L",
        "outputId": "77e2914a-8039-4a87-c875-7cdf3faf43e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "word2vec_model=api.load(\"word2vec-google-news-300\")\n",
        "gloVe_model=api.load(\"glove-wiki-gigaword-300\")\n",
        "fast_model=api.load(\"fasttext-wiki-news-subwords-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kUs2TVXZmYR",
        "outputId": "067784bf-e293-4c10-842b-5c684f5fc485"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n",
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "\n",
        "# Ensure downloads\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Clean and tokenize sentence\n",
        "def get_filtered_tokens(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    return [token for token in tokens if token.isalpha() and token not in stop_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25lD1vnZfi9I",
        "outputId": "6feffc48-86c7-4044-f260-78e0f92948ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp20SjJwbIUH",
        "outputId": "ab5f95dc-38f0-4630-bc8d-704d84d157a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def avr_embeding(text,model):\n",
        "  tokens=word_tokenize(text)\n",
        "  word_vectors=[model[word] for word in tokens if word in model]\n",
        "  if not word_vectors:\n",
        "    return np\n",
        "  else:\n",
        "   return np.mean(word_vectors,axis=0)"
      ],
      "metadata": {
        "id": "J3JnLoJmaaHd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Step 1: Vectorize all sentences\n",
        "vectorizer = CountVectorizer().fit(data)\n",
        "vectors = vectorizer.transform(data)\n",
        "\n",
        "# Step 2: Compute pairwise cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(vectors)\n",
        "\n",
        "# Step 3: Print the matrix\n",
        "print(\"Cosine Similarity Matrix:\")\n",
        "for row in similarity_matrix:\n",
        "    print(\"\\t\".join(f\"{value:.2f}\" for value in row))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flTyowVrf4kS",
        "outputId": "a524754a-0e4a-4fab-8e6b-4780fa8129c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity Matrix:\n",
            "1.00\t0.25\t0.00\t0.00\n",
            "0.25\t1.00\t0.00\t0.00\n",
            "0.00\t0.00\t1.00\t0.00\n",
            "0.00\t0.00\t0.00\t1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim"
      ],
      "metadata": {
        "id": "4XUKVYb4gTyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_vectors=np.array([avr_embeding(sentence,word2vec_model) for sentence in data])\n",
        "similarity_matrix=cosine_similarity(avg_vectors)\n",
        "print(similarity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm1Q59QDfpz-",
        "outputId": "d746ea9f-c3dc-443f-812e-1f3cd60f4466"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9999998  0.45016417 0.37918076 0.2623811 ]\n",
            " [0.45016417 0.9999998  0.39407733 0.32117078]\n",
            " [0.37918076 0.39407733 1.0000002  0.4630655 ]\n",
            " [0.2623811  0.32117078 0.4630655  0.99999994]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe"
      ],
      "metadata": {
        "id": "gIGcZL4VgN59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_vectors=np.array([avr_embeding(sentence,gloVe_model) for sentence in data])\n",
        "similarity_matrix=cosine_similarity(avg_vectors)\n",
        "print(similarity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzkFApIegBPZ",
        "outputId": "4d2d4ffd-7125-480c-ee86-0ceef58aa2f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99999994 0.6256172  0.5480732  0.35537183]\n",
            " [0.6256172  0.99999976 0.49188027 0.3523824 ]\n",
            " [0.5480732  0.49188027 1.0000001  0.47376773]\n",
            " [0.35537183 0.3523824  0.47376773 0.9999996 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fasttext"
      ],
      "metadata": {
        "id": "7hjxlKQHgO6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_vectors=np.array([avr_embeding(sentence,fast_model) for sentence in data])\n",
        "similarity_matrix=cosine_similarity(avg_vectors)\n",
        "print(similarity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyzBnyU-gExx",
        "outputId": "94606901-7b40-4633-a899-69c1c3527525"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9999997  0.6155418  0.6612374  0.64005744]\n",
            " [0.6155418  1.         0.58614075 0.61035746]\n",
            " [0.6612374  0.58614075 1.0000002  0.7446791 ]\n",
            " [0.64005744 0.61035746 0.7446791  0.99999994]]\n"
          ]
        }
      ]
    }
  ]
}